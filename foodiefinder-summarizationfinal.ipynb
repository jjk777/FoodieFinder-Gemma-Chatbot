{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9554838,"sourceType":"datasetVersion","datasetId":5822065},{"sourceId":11372,"sourceType":"modelInstanceVersion","modelInstanceId":5388,"modelId":3533}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LOAD LIBRARIES","metadata":{}},{"cell_type":"code","source":"import keras\nimport keras_nlp","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LOAD GEMMA MODEL","metadata":{}},{"cell_type":"code","source":"%%time\n# Load Language Model via Keras\nLLM = keras_nlp.models.GemmaCausalLM.from_preset('gemma_instruct_2b_en')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Note:** The \"restaurant-overview-summarization\" dataset was generated using a local notebook. This notebook processes restaurant and menu data, performs tasks such as data cleaning (including text translation), creates additional features and combine the reviews data generated by \"FoodieFinder_Summarization_Base\" kaggle notebook.\n\nGithub link to the notebook (FoodieFinder_CombineRestaurantData_FeatureEngineering):","metadata":{}},{"cell_type":"markdown","source":"# READ THE DATA","metadata":{}},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/restaurant-overview-summarization/reviews_df_1.csv\")\ndf2 = pd.read_csv(\"/kaggle/input/restaurant-overview-summarization/reviews_df_2.csv\")\ndf3 = pd.read_csv(\"/kaggle/input/restaurant-overview-summarization/reviews_df_3.csv\")\ndf4 = pd.read_csv(\"/kaggle/input/restaurant-overview-summarization/reviews_df_4.csv\")\ndf5 = pd.read_csv(\"/kaggle/input/restaurant-overview-summarization/reviews_df_5.csv\")\ndf = pd.concat([df1,df2,df3,df4,df5])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.shape)\ndf.drop_duplicates(inplace=True)\nprint(df.shape)\ndf.head(1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.rename(columns = {'summarized_comments':'review'}, inplace = True)\ndf.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df[['restaurant_name','location','categories','translated_address', 'district', 'rating', 'selected_dishes', 'price', 'review']]\ndf.head(1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TEXT SUMMARIZATION","metadata":{}},{"cell_type":"code","source":"# Function to summarize reviews for a single restaurant\ndef summarize_reviews(reviews):\n    # Concatenate all the reviews into a single text\n    combined_reviews = \" \".join(reviews)    \n    prompt = (\n        \"Summarize the following reviews in detail in paragraphs. Include information about menu items, highlight both positive and negative aspects, \"\n        \"and avoid adding any external or irrelevant information. Keep the summary factual \"\n        \"and honest to reflect what customers truly feel about the restaurant:\\n\\n\"\n        f\"{combined_reviews}\\n\\n\"\n        \"Summarized review:\"\n    )\n\n    # Generate the summarized review\n    summarized_review = LLM.generate([prompt], max_length=2000)[0]\n    \n    return combined_reviews,summarized_review\n\n# Group by restaurant name and summarize the reviews\ndef create_summarized_reviews_df(df):\n    summarized_reviews = []\n    \n    # Group the dataframe by 'restaurant_name'\n    grouped_reviews = df.groupby('restaurant_name')['review'].apply(list)\n    \n    # Loop through each group and summarize the reviews\n    for restaurant_name, reviews in grouped_reviews.items():\n        # Summarize all reviews for this restaurant\n        context,summarized_review = summarize_reviews(reviews)\n        \n        # Append to the list as a dictionary\n        summarized_reviews.append({\n            'context': context,\n            'restaurant_name': restaurant_name,\n            'summarized_review': summarized_review\n        })\n    \n    # Create a new dataframe from the summarized reviews\n    summary_df = pd.DataFrame(summarized_reviews)\n    \n    return summary_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nsummary_df = create_summarized_reviews_df(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop 'price' and 'review' columns from df\ndf_cleaned = df.drop(columns=['review'])\n\n# Drop duplicates from df based on the 'restaurant_name' column\ndf_cleaned = df_cleaned.drop_duplicates()\n\n# Perform the left join\nmerged_df = pd.merge(summary_df, df_cleaned, on='restaurant_name', how='left')\nprint(merged_df.shape)\nmerged_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SAVE THE OUTPUT","metadata":{}},{"cell_type":"code","source":"# Save to CSV\nmerged_df.to_csv(\"merged_df_generated.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.to_csv(\"dataset_used.csv\", index=False) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}