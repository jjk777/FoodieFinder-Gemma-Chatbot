{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - tried scrapping 1000 restaurants. For the review links function, after 25 mins the extraction stopped as the connection was forcibly closed by the remote host. Was extracting too much information :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The restaurant URL is  https://tabelog.com/en/hokkaido/rstLst/\n",
      "The number of restaurants to scrap 100\n"
     ]
    }
   ],
   "source": [
    "## DOMAIN = 'https://tabelog.com/'\n",
    "targeted_region = 'hokkaido'  # tokyo, osaka, kyoto, hokkaido\n",
    "RESTAURANT_URL = 'https://tabelog.com/en/' + targeted_region + '/rstLst/'\n",
    "page = 5 # number of restaurants, 1 page = 20 restaurants\n",
    "\n",
    "print(\"The restaurant URL is \", RESTAURANT_URL)\n",
    "print(\"The number of restaurants to scrap\", page*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Restaurant Details Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function helps to get the restaurant URLs\n",
    "\"\"\"\n",
    "def get_url(page):\n",
    "    url_list = []\n",
    "    \n",
    "    for i in range(page):\n",
    "        url = RESTAURANT_URL + str(i) + '/'\n",
    "        #print(\"URL is \",url)\n",
    "        \n",
    "        # Send a request to the URL\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        #print(\"Type of soup is\",type(soup))\n",
    "        #print(\"Soup is\",soup)\n",
    "       \n",
    "        \n",
    "        # grab \"https://tabelog.com/en/tokyo/A1317/A131712/13171774/\"\n",
    "        restaurants = soup.findAll(\"a\", {\"list-rst__rst-name-target cpy-rst-name\"},href=True) \n",
    "        #print(\"restaurants are:\", restaurants)\n",
    "\n",
    "        for res in restaurants:\n",
    "            url_list.append(res['href'])\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 469 ms\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "restaurant_links = get_url(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://tabelog.com/en/hokkaido/A0101/A010103/1072073/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1064993/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1003634/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1004125/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1028665/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1069091/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1008057/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1073252/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1077231/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010104/1000249/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1071005/',\n",
       " 'https://tabelog.com/en/hokkaido/A0104/A010401/1068350/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1044921/',\n",
       " 'https://tabelog.com/en/hokkaido/A0104/A010403/1058891/',\n",
       " 'https://tabelog.com/en/hokkaido/A0105/A010501/1028734/',\n",
       " 'https://tabelog.com/en/hokkaido/A0105/A010501/1060964/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1057421/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010102/1077465/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1077163/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1070312/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1072073/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1064993/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1003634/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1004125/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1028665/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1069091/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1008057/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1073252/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1077231/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010104/1000249/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1071005/',\n",
       " 'https://tabelog.com/en/hokkaido/A0104/A010401/1068350/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1044921/',\n",
       " 'https://tabelog.com/en/hokkaido/A0104/A010403/1058891/',\n",
       " 'https://tabelog.com/en/hokkaido/A0105/A010501/1028734/',\n",
       " 'https://tabelog.com/en/hokkaido/A0105/A010501/1060964/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1057421/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010102/1077465/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1077163/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1070312/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010101/1078955/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010101/1069025/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010101/1061233/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1065846/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010101/1020704/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1077075/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010102/1073682/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010101/1004828/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010105/1041093/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010102/1077385/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1003835/',\n",
       " 'https://tabelog.com/en/hokkaido/A0111/A011101/1052080/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1060818/',\n",
       " 'https://tabelog.com/en/hokkaido/A0107/A010701/1057504/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1001632/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1062547/',\n",
       " 'https://tabelog.com/en/hokkaido/A0111/A011101/1076993/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1010304/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010101/1004824/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1059920/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010101/1002771/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1069771/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1059809/',\n",
       " 'https://tabelog.com/en/hokkaido/A0111/A011101/1070638/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1060029/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1078057/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010102/1077384/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1068212/',\n",
       " 'https://tabelog.com/en/hokkaido/A0104/A010401/1066040/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1074335/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1046792/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1008086/',\n",
       " 'https://tabelog.com/en/hokkaido/A0104/A010401/1055861/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010101/1057748/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010104/1064029/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1000873/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1000357/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1060859/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010102/1007595/',\n",
       " 'https://tabelog.com/en/hokkaido/A0108/A010802/1000858/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010204/1048369/',\n",
       " 'https://tabelog.com/en/hokkaido/A0108/A010802/1079119/',\n",
       " 'https://tabelog.com/en/hokkaido/A0106/A010601/1053984/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010101/1066311/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1008075/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1076206/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1075068/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1048643/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010301/1053312/',\n",
       " 'https://tabelog.com/en/hokkaido/A0110/A011003/1021630/',\n",
       " 'https://tabelog.com/en/hokkaido/A0111/A011101/1072978/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1064197/',\n",
       " 'https://tabelog.com/en/hokkaido/A0104/A010401/1065949/',\n",
       " 'https://tabelog.com/en/hokkaido/A0112/A011201/1001991/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1058253/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1014667/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010201/1063202/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010103/1043598/',\n",
       " 'https://tabelog.com/en/hokkaido/A0101/A010102/1001730/',\n",
       " 'https://tabelog.com/en/hokkaido/A0105/A010501/1063331/']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://tabelog.com/en/hokkaido/A0101/A010103/1028665/'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(restaurant_links))\n",
    "restaurant_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "This function will store the restaurant details. The details include name, categories, phone number, reservation, transport, address, opening hours, average price, average price based on reviews, payments, service charge, receipt\n",
    "\"\"\"\n",
    "\n",
    "def scrape(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    # <table class=\"c-table rd-detail-info\">\n",
    "    table = soup.find(\"table\", class_ = \"c-table c-table--form rstinfo-table__table\") \n",
    "    #print(table)\n",
    "    rows = table.tbody.find_all('tr')\n",
    "    \n",
    "    res_info = {}\n",
    "    for row in rows:\n",
    "        res_info[row.find('th').text.strip()] = row.find('td').text.strip().replace('\\n','')\n",
    "#     print(res_info)\n",
    "    \n",
    "    return res_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.45 s\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "restaurants_info = []\n",
    "for url in restaurant_links:\n",
    "    cur_restaurant = scrape(url)\n",
    "    restaurants_info.append(cur_restaurant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Phone number (for reservation and inquiry)</th>\n",
       "      <th>Reservation availability</th>\n",
       "      <th>Address</th>\n",
       "      <th>Transportation</th>\n",
       "      <th>Opening hours</th>\n",
       "      <th>Average price</th>\n",
       "      <th>Average price（Based on reviews）</th>\n",
       "      <th>Payment methods</th>\n",
       "      <th>Receipt (Qualified simple invoice)</th>\n",
       "      <th>Service charge &amp; fee</th>\n",
       "      <th>Awards &amp; Recognitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kyoto Sushi Momonoki</td>\n",
       "      <td>Sushi, Seafood</td>\n",
       "      <td>050-5600-6934</td>\n",
       "      <td>Reservations available                        ...</td>\n",
       "      <td>京都府京都市下京区真苧屋町99 ブーケガルニ B1F                    ...</td>\n",
       "      <td>Subway Toshima Line / Kyoto Station 4 minutes ...</td>\n",
       "      <td>Mon, Tue, Wed, Thu, Fri                       ...</td>\n",
       "      <td>JPY 10,000 - JPY 14,999JPY 4,000 - JPY 4,999</td>\n",
       "      <td>JPY 20,000 - JPY 29,999JPY 6,000 - JPY 7,999Vi...</td>\n",
       "      <td>Credit card accepted                          ...</td>\n",
       "      <td>Qualified invoice (receipt) availableRegistrat...</td>\n",
       "      <td>Service charge 10%                            ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Restaurant name      Categories  \\\n",
       "0  Kyoto Sushi Momonoki  Sushi, Seafood   \n",
       "\n",
       "  Phone number (for reservation and inquiry)  \\\n",
       "0                              050-5600-6934   \n",
       "\n",
       "                            Reservation availability  \\\n",
       "0  Reservations available                        ...   \n",
       "\n",
       "                                             Address  \\\n",
       "0  京都府京都市下京区真苧屋町99 ブーケガルニ B1F                    ...   \n",
       "\n",
       "                                      Transportation  \\\n",
       "0  Subway Toshima Line / Kyoto Station 4 minutes ...   \n",
       "\n",
       "                                       Opening hours  \\\n",
       "0  Mon, Tue, Wed, Thu, Fri                       ...   \n",
       "\n",
       "                                  Average price  \\\n",
       "0  JPY 10,000 - JPY 14,999JPY 4,000 - JPY 4,999   \n",
       "\n",
       "                     Average price（Based on reviews）  \\\n",
       "0  JPY 20,000 - JPY 29,999JPY 6,000 - JPY 7,999Vi...   \n",
       "\n",
       "                                     Payment methods  \\\n",
       "0  Credit card accepted                          ...   \n",
       "\n",
       "                  Receipt (Qualified simple invoice)  \\\n",
       "0  Qualified invoice (receipt) availableRegistrat...   \n",
       "\n",
       "                                Service charge & fee Awards & Recognitions  \n",
       "0  Service charge 10%                            ...                   NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(restaurants_info)\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"output/\"+targeted_region+\"_restaurant_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Restaurant Menu Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_menu_links = [link.rsplit('/', 1)[0] + '/dtlmenu/' for link in restaurant_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://tabelog.com/en/hokkaido/A0101/A010101/1020704/dtlmenu/'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_menu_links[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://tabelog.com/en/hokkaido/A0101/A010102/1078638/dtlmenu/'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_menu_links[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(restaurant_menu_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to scrape restaurant name and menu titles from a single URL\n",
    "def get_menu_data(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find restaurant name using the specified class\n",
    "        restaurant_name_tag = soup.find('h2', class_='display-name')\n",
    "        restaurant_name = restaurant_name_tag.get_text(strip=True) if restaurant_name_tag else \"No name found\"\n",
    "        \n",
    "        # Find all menu titles with the specified class\n",
    "        titles = soup.find_all('p', class_='rstdtl-menu-lst__menu-title')\n",
    "        #print(\"titles\", titles)\n",
    "        menu_titles = [title.get_text(strip=True) for title in titles]\n",
    "        \n",
    "        return restaurant_name, menu_titles\n",
    "    else:\n",
    "        #print(\"inside else\")\n",
    "        return \"No response\", []\n",
    "\n",
    "# # Iterate through all links and print the restaurant name and titles\n",
    "# for link in restaurant_menu_links:\n",
    "#     print(f\"Scraping data for {link}:\")\n",
    "#     restaurant_name, titles = get_menu_data(link)\n",
    "#     print(f\"Restaurant: {restaurant_name}\")\n",
    "#     print(\"Menu titles:\")\n",
    "#     for title in titles:\n",
    "#         print(f\"- {title}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.23 s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create an empty list to store the data\n",
    "menu_data = []\n",
    "\n",
    "# Iterate through all links and store the restaurant name and menu titles in the list\n",
    "for link in restaurant_menu_links:\n",
    "    restaurant_name, titles = get_menu_data(link)\n",
    "    \n",
    "    # If no titles are found, append a row with just the restaurant name and blank dishes\n",
    "    if not titles:\n",
    "        menu_data.append({\n",
    "            'restaurant_name': restaurant_name,\n",
    "            'dishes': ''\n",
    "        })\n",
    "    else:\n",
    "        # Store each menu title along with the restaurant name\n",
    "        for title in titles:\n",
    "            menu_data.append({\n",
    "                'restaurant_name': restaurant_name,\n",
    "                'dishes': title\n",
    "            })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "menu_df = pd.DataFrame(menu_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#menu_df[\"location\"] = targeted_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4463, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant_name</th>\n",
       "      <th>dishes</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AKI NAGAO</td>\n",
       "      <td>akinagao Chef'sCourse Akinagao selection Course</td>\n",
       "      <td>hokkaido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L'Oiseau par Matsunaga</td>\n",
       "      <td></td>\n",
       "      <td>hokkaido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAJIME</td>\n",
       "      <td>Cow tongue tongue shabu-shabu shabu shabu</td>\n",
       "      <td>hokkaido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAJIME</td>\n",
       "      <td>Lamb shabu set Lamb shabu set</td>\n",
       "      <td>hokkaido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAJIME</td>\n",
       "      <td>Cow tongue tongue shabu-shabu</td>\n",
       "      <td>hokkaido</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          restaurant_name                                           dishes  \\\n",
       "0               AKI NAGAO  akinagao Chef'sCourse Akinagao selection Course   \n",
       "1  L'Oiseau par Matsunaga                                                    \n",
       "2                  HAJIME        Cow tongue tongue shabu-shabu shabu shabu   \n",
       "3                  HAJIME                    Lamb shabu set Lamb shabu set   \n",
       "4                  HAJIME                    Cow tongue tongue shabu-shabu   \n",
       "\n",
       "   location  \n",
       "0  hokkaido  \n",
       "1  hokkaido  \n",
       "2  hokkaido  \n",
       "3  hokkaido  \n",
       "4  hokkaido  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(menu_df.shape)\n",
    "menu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_df.to_csv(\"output/\"+targeted_region+\"_restaurant_menu_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Restaurant Reviews Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "This function will give us links to reviews page of the restaurants\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_url2(my_url):\n",
    "    r = requests.get(my_url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    # Find the 'a' tag with the class 'c-link-circle'\n",
    "    link = soup.find('a', class_='c-link-circle')\n",
    "\n",
    "    # Extract the 'href' attribute only\n",
    "    if link:\n",
    "        review_url = link.get('href')\n",
    "\n",
    "        # everything after the last forward slash should be replaced with 'dtlrvwlist'\n",
    "        if 'party' in review_url or review_url.endswith('/'):\n",
    "            review_url = review_url.rsplit('/party/', 1)[0] + '/dtlrvwlst/'\n",
    "        else:\n",
    "            review_url = None # or return the review_url itself\n",
    "\n",
    "        #print(\"Modified Review link:\", review_url)\n",
    "        return review_url\n",
    "    else:\n",
    "        #print(\"No review link found.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.52 s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "review_links = []\n",
    "for my_url in restaurant_links:\n",
    "    cur_review = get_url2(my_url)\n",
    "    review_links.append(cur_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://tabelog.com/en/tokyo/A1306/A130602/13042979/dtlrvwlst/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(review_links))\n",
    "review_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\" \n",
    "Since, full review is not in the links grabbed above, therefore we will get the full review by clicking on the view_more button. This information will be in a new URL.\n",
    "\"\"\"\n",
    "\n",
    "def get_url3(my_url):\n",
    "    # Send a request to the URL\n",
    "    r = requests.get(my_url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    # Find all 'span' elements with the class 'rvw-showall-trigger__target js-link-bookmark-detail'\n",
    "    review_links = soup.find_all('span', class_='rvw-showall-trigger__target js-link-bookmark-detail')\n",
    "\n",
    "    # Extract the 'data-detail-url' attribute for each review\n",
    "    review_urls = []\n",
    "    for review in review_links:\n",
    "        data_url = review.get('data-detail-url')\n",
    "        if data_url:\n",
    "            review_urls.append(data_url)\n",
    "\n",
    "    return(review_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.08 s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "review_link_info_page = []\n",
    "\n",
    "for my_url in review_links:\n",
    "    cur_review_url = get_url3(my_url)\n",
    "    review_link_info_page .append(cur_review_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(review_link_info_page ))\n",
    "print(len(review_link_info_page[60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B472913068/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B482102684/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B472972295/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B477251744/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B474609437/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B492575294/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B492645672/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B492673452/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B484356982/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B491688898/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B490889634/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B491186649/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B491299097/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B490633352/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B490533235/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B490531594/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B490836425/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B490596863/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B490685670/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B490401395/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B489977949/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B490074100/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B489794216/?smp=0&use_type=0',\n",
       " 'https://tabelog.com/en/tokyo/A1303/A130301/13289319/dtlrvwlst/B489616943/?smp=0&use_type=0']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_link_info_page[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Grab all the information from the new review URL. This includes - the review, the restaurant name and ratings\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_reviews(my_url):\n",
    "\n",
    "    r = requests.get(my_url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    # Extract the restaurant name from <h2 class=\"display-name\">\n",
    "    restaurant_name_tag = soup.find('h2', class_='display-name')\n",
    "    if restaurant_name_tag:\n",
    "        restaurant_name = restaurant_name_tag.get_text(strip=True)\n",
    "        #print(\"Restaurant Name:\", restaurant_name)\n",
    "    else:\n",
    "        restaurant_name = None\n",
    "        #print(\"No restaurant name found.\")\n",
    "\n",
    "    # Extract the total restaurant rating from <ul class=\"rdheader-counts\">\n",
    "    total_restaurant_rating_tag = soup.find('ul', class_='rdheader-counts')\n",
    "    if total_restaurant_rating_tag :\n",
    "        total_restaurant_rating= total_restaurant_rating_tag.get_text(strip=True)\n",
    "        #print(\"Total Rating:\", total_restaurant_rating)\n",
    "    else:\n",
    "        total_restaurant_rating = None\n",
    "        #print(\"No total rating found.\")\n",
    "\n",
    "    # Extract the ratings div\n",
    "    individual_rating_div = soup.find('div', class_='rvw-item__single-ratings')\n",
    "    if individual_rating_div:\n",
    "        individual_rating_info = individual_rating_div.get_text(strip=True)\n",
    "        #print(\"Individual Rating Info:\", individual_rating_info)\n",
    "    else:\n",
    "        individual_rating_info = None\n",
    "        #print(\"No individual rating info found.\")\n",
    "\n",
    "    # Extract the comment div\n",
    "    comment_div = soup.find('div', class_='rvw-item__rvw-comment rvw-item__rvw-comment--custom')\n",
    "    if comment_div:\n",
    "        comment_info = comment_div.get_text(strip=True)\n",
    "        #print(\"Comment Info:\", comment_info)\n",
    "    else:\n",
    "        comment_info = None\n",
    "        #print(\"No comment info found.\")\n",
    "\n",
    "    return {\n",
    "        'restaurant_name': restaurant_name,\n",
    "        'restaurant_rating': total_restaurant_rating,\n",
    "        'individual_rating': individual_rating_info,\n",
    "        'comments': comment_info\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.8 s\n",
      "Wall time: 43min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "detailed_reviews = []\n",
    "\n",
    "for review_data in review_link_info_page:\n",
    "    for i in review_data:\n",
    "        review_details = get_reviews(i)\n",
    "        detailed_reviews.append(review_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1590, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant_name</th>\n",
       "      <th>restaurant_rating</th>\n",
       "      <th>individual_rating</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hokkaido Shabushabu Pokke Dai3 Gurin Biru Ten</td>\n",
       "      <td>3.2123reviews</td>\n",
       "      <td>3.6Food and taste-Service-Atmosphere-Cost perf...</td>\n",
       "      <td>All-you-can-eat lamb and pork. And all you can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hokkaido Shabushabu Pokke Dai3 Gurin Biru Ten</td>\n",
       "      <td>3.2123reviews</td>\n",
       "      <td>1.0Food and taste3.0Service1.0Atmosphere1.0Cos...</td>\n",
       "      <td>The restaurant I was planning to go to was clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hokkaido Shabushabu Pokke Dai3 Gurin Biru Ten</td>\n",
       "      <td>3.2123reviews</td>\n",
       "      <td>4.0Food and taste4.0Service3.6Atmosphere3.6Cos...</td>\n",
       "      <td>My favorite Pokke-san after a long time. Today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hokkaido Shabushabu Pokke Dai3 Gurin Biru Ten</td>\n",
       "      <td>3.2123reviews</td>\n",
       "      <td>3.3Food and taste3.3Service3.0Atmosphere3.0Cos...</td>\n",
       "      <td>I came to visit after realizing that I had nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hokkaido Shabushabu Pokke Dai3 Gurin Biru Ten</td>\n",
       "      <td>3.2123reviews</td>\n",
       "      <td>3.0Food and taste3.0Service3.0Atmosphere2.0Cos...</td>\n",
       "      <td>Assorted vegetables Meat I think the price is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 restaurant_name restaurant_rating  \\\n",
       "0  Hokkaido Shabushabu Pokke Dai3 Gurin Biru Ten     3.2123reviews   \n",
       "1  Hokkaido Shabushabu Pokke Dai3 Gurin Biru Ten     3.2123reviews   \n",
       "2  Hokkaido Shabushabu Pokke Dai3 Gurin Biru Ten     3.2123reviews   \n",
       "3  Hokkaido Shabushabu Pokke Dai3 Gurin Biru Ten     3.2123reviews   \n",
       "4  Hokkaido Shabushabu Pokke Dai3 Gurin Biru Ten     3.2123reviews   \n",
       "\n",
       "                                   individual_rating  \\\n",
       "0  3.6Food and taste-Service-Atmosphere-Cost perf...   \n",
       "1  1.0Food and taste3.0Service1.0Atmosphere1.0Cos...   \n",
       "2  4.0Food and taste4.0Service3.6Atmosphere3.6Cos...   \n",
       "3  3.3Food and taste3.3Service3.0Atmosphere3.0Cos...   \n",
       "4  3.0Food and taste3.0Service3.0Atmosphere2.0Cos...   \n",
       "\n",
       "                                            comments  \n",
       "0  All-you-can-eat lamb and pork. And all you can...  \n",
       "1  The restaurant I was planning to go to was clo...  \n",
       "2  My favorite Pokke-san after a long time. Today...  \n",
       "3  I came to visit after realizing that I had nev...  \n",
       "4  Assorted vegetables Meat I think the price is ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.DataFrame(detailed_reviews).head()\n",
    "final_review_df = pd.DataFrame.from_dict(detailed_reviews)\n",
    "print(final_review_df.shape)\n",
    "final_review_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_review_df.to_csv(\"output/\"+targeted_region+\"_restaurant_review_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KaggleXEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
